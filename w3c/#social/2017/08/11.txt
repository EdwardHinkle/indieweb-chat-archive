2017-08-11 02:10:38.359000 {"type":"message","timestamp":"1502417438.359000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"Gargron","nickname":"Gargron","name":"Gargron","username":null},"content":"puckipedia: https:\/\/github.com\/tootsuite\/mastodon\/pull\/4566 please try this PR if you can"}
2017-08-11 02:10:39.868000 {"type":"message","timestamp":"1502417439.868000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"Loqi","nickname":"Loqi","name":"Loqi","username":null},"content":"[Gargron] #4566 ActivityPub delivery"}
2017-08-11 02:17:21.333000 {"type":"message","timestamp":"1502417841.333000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"a batch delivery endpoint would be cool. would just need to define what the response should look like. That could be a new eternal bikeshed..."}
2017-08-11 02:27:25.344000 {"type":"message","timestamp":"1502418445.344000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"it also might be nice, similarly, that a response could tell the other server how many items are waiting for pickup and perhaps a list of ids"}
2017-08-11 02:28:14.359000 {"type":"message","timestamp":"1502418494.359000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"only problem there is how to prevent the race between delivery and pickup"}
2017-08-11 04:45:19.000000 {"type":"message","timestamp":"1502426719.000000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"Loqi","nickname":"Loqi","name":"Loqi","username":null},"content":"[@RoLLodeQc] @omarqazi @BenedictEvans @gassee https:\/\/www.w3.org\/TR\/activitypub\/ for instance (http:\/\/twtr.io\/1Utk1R5VL4H)"}
2017-08-11 05:18:24.339000 {"type":"message","timestamp":"1502428704.339000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"xmpp-social","nickname":"xmpp-social","name":"xmpp-social","username":null},"content":"[ajordan] saranix: define \"pickup\""}
2017-08-11 05:18:55.981000 {"type":"message","timestamp":"1502428735.981000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"xmpp-social","nickname":"xmpp-social","name":"xmpp-social","username":null},"content":"[ajordan] I also have yet to see how an explicit batch delivery system would solve things HTTP\/2 doesn't"}
2017-08-11 06:25:30.259000 {"type":"join","timestamp":"1502432730.259000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"xmpp-social","nickname":"xmpp-social","name":"xmpp-social","username":null},"content":""}
2017-08-11 06:51:53.954000 {"type":"message","timestamp":"1502434313.954000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"ajordan: I'm referring to the situation where you have an output queue of stuff to send to someone, and luck would have it, they are posting to you before you get around to it. You then maybe have the option of giving it to them or at least telling them about it. If you tell them about it, they will need another round trip to \"pick it up\", but if you send it unsolicited that's no good cause that's a ton,"}
2017-08-11 06:52:34.760000 {"type":"message","timestamp":"1502434354.760000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"... the other problem is then do you remove it from your output queue (presumably a separate e.g. cron process) or race the other server to pick it up"}
2017-08-11 06:52:53.206000 {"type":"message","timestamp":"1502434373.206000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"ajordan: you have a very good point about http2 though"}
2017-08-11 06:55:22.675000 {"type":"message","timestamp":"1502434522.675000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"and if they pick it up, can they do bulk pick up.. e.g. \"give me all of these ids: \"..."}
2017-08-11 07:02:38.988000 {"type":"message","timestamp":"1502434958.988000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"the latter case would be helpful regardless of queue notification, a server might just collect a slew of refs to load from particular servers which are popular. It would be great if auth\/permissions checks can be done once and several pulled to save time bandwidth computation etc"}
2017-08-11 07:03:32.258000 {"type":"message","timestamp":"1502435012.258000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"plus good lord latency if you are talking busy server, say 100s of users in a big popular news story convo"}
2017-08-11 07:03:41.460000 {"type":"message","timestamp":"1502435021.460000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"likes and shares going around like crazy"}
2017-08-11 08:47:19.116000 {"type":"message","timestamp":"1502441239.116000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"saranix","nickname":"saranix","name":"saranix","username":null},"content":"*without* batching, you are pretty much mandating p2p swarm-style connection pooling e.g. 20-50 connections at a time so that one individual taking a long time doesn't slow the whole thing down, plus backoffs for slow-responders etc. like I said p2p-like"}
2017-08-11 22:02:21.040000 {"type":"join","timestamp":"1502488941.040000","network":"irc","server":"w3c","channel":{"id":"#social","name":"#social"},"author":{"uid":"eugr","nickname":"eugr","name":"eugr","username":null},"content":""}
